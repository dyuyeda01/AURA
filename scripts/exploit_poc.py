# scripts/exploit_poc.py
"""
Robust Exploit-DB PoC extractor (Exploit-DB only)
Tries multiple search endpoints and multiple extraction strategies to return:
    (has_poc: bool, edb_ids: List[str], urls: List[str])
"""

from typing import Tuple, List
import re
import time
import logging
import requests

log = logging.getLogger(__name__)

# Try multiple search endpoints — some pages respond differently
SEARCH_URLS = [
    "https://www.exploit-db.com/search?q={cve}",      # old approach
    "https://www.exploit-db.com/search?cve={cve}",    # alternative param
    "https://www.exploit-db.com/search?term={cve}",   # another possible param
]
REQUEST_TIMEOUT = 10
MAX_LINKS = 10
USER_AGENT = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_6) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
)


def _extract_edb_ids_and_urls_from_html(text: str) -> Tuple[List[str], List[str]]:
    """Try multiple patterns to find /exploits/<id> links and EDB ids."""
    edb_ids: List[str] = []
    urls: List[str] = []

    # 1) direct hrefs /exploits/<id> or /exploits/<id>/<slug>
    for m in re.findall(r'href=["\'](/exploits/(\d+)(?:[^"\']*)?)["\']', text, flags=re.I):
        relpath, edb = m[0], m[1]
        full = "https://www.exploit-db.com" + relpath
        if edb not in edb_ids:
            edb_ids.append(edb)
        if full not in urls:
            urls.append(full)

    # 2) absolute links containing /exploits/<id>
    for m in re.findall(r'(https?://[^"\'>\s]*?/exploits/(\d+)(?:[^"\'>\s]*)?)', text, flags=re.I):
        full, edb = m[0], m[1]
        if edb not in edb_ids:
            edb_ids.append(edb)
        if full not in urls:
            urls.append(full)

    # 3) data-href attributes or other attributes
    for m in re.findall(r'data-href=["\']([^"\']*/exploits/(\d+)[^"\']*)["\']', text, flags=re.I):
        relpath, edb = m[0], m[1]
        full = relpath if relpath.startswith("http") else "https://www.exploit-db.com" + relpath
        if edb not in edb_ids:
            edb_ids.append(edb)
        if full not in urls:
            urls.append(full)

    # 4) /download/ links sometimes accompany exploits (capture those too)
    for m in re.findall(r'href=["\'](/download/\d+(?:[^"\']*)?)["\']', text, flags=re.I):
        relpath = m
        full = "https://www.exploit-db.com" + relpath
        # try to map download links to exploits by searching nearby for /exploits/<id>
        if full not in urls:
            urls.append(full)

    # 5) JSON or JS blobs: search inside script tags for "/exploits/<id>"
    #    Find any occurrence of /exploits/<id> anywhere in text
    for m in re.findall(r'/exploits/(\d+)', text):
        edb = m
        link = f"https://www.exploit-db.com/exploits/{edb}"
        if edb not in edb_ids:
            edb_ids.append(edb)
        if link not in urls:
            urls.append(link)

    # dedupe with order preserved
    seen = set()
    out_urls = []
    out_ids = []
    for u, e in zip(urls, (edb_ids + [''] * len(urls))):
        if u not in seen:
            seen.add(u)
            out_urls.append(u)
    for e in edb_ids:
        if e not in out_ids:
            out_ids.append(e)

    return out_ids[:MAX_LINKS], out_urls[:MAX_LINKS]


def has_exploit_poc(cve_id: str) -> Tuple[bool, List[str], List[str]]:
    """
    Return (has_poc, edb_ids, urls).
    Tries multiple search URL patterns and extraction heuristics.
    Falls back to returning search URL if CVE is present but no direct link extracted.
    """
    headers = {"User-Agent": USER_AGENT}
    last_exc = None

    for base in SEARCH_URLS:
        url = base.format(cve=cve_id)
        try:
            r = requests.get(url, timeout=REQUEST_TIMEOUT, headers=headers)
            r.raise_for_status()
            text = r.text or ""
            # quick presence check
            if cve_id not in text:
                # CVE not present on this endpoint — try next
                continue

            # attempt robust extraction
            edb_ids, links = _extract_edb_ids_and_urls_from_html(text)

            if edb_ids or links:
                # Prefer EDB ids + links found
                return True, edb_ids, links

            # If CVE present but we couldn't find direct links, attempt to search script tags more aggressively:
            # look for JSON-looking blocks that may contain exploits entries
            script_snippets = re.findall(r'<script[^>]*>(.*?)</script>', text, flags=re.S | re.I)
            for s in script_snippets:
                if '/exploits/' in s or 'exploits' in s:
                    edb_ids2, links2 = _extract_edb_ids_and_urls_from_html(s)
                    if edb_ids2 or links2:
                        return True, edb_ids2, links2

            # fallback: CVE present but no direct link — return the search URL so UI can at least show search
            return True, [], [url]

        except Exception as e:
            last_exc = e
            log.debug(f"[ExploitDB] error checking {url} for {cve_id}: {e}")
            time.sleep(0.25)

    # nothing found across endpoints
    if last_exc:
        log.debug(f"[ExploitDB] last exception: {last_exc}")
    return False, [], []
